{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer Implementation & Comparison with Sklearn's CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountVectorizer:\n",
    "    \"\"\"\n",
    "    The CountVectorizer class is used for transforming text sequences into\n",
    "    numerical vectors.\n",
    "\n",
    "    Input:\n",
    "        ngram_size (int): The size of the ngrams to be used for tokenization.\n",
    "\n",
    "    Attributes:\n",
    "        ngram_size (int): The size of the ngrams used for tokenization.\n",
    "        vocabulary (dict): The vocabulary built during fitting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_size):\n",
    "        if not isinstance(ngram_size, int) or ngram_size <= 0:\n",
    "            raise ValueError(\"ngram_size must be a positive integer.\")\n",
    "        self.ngram_size = ngram_size\n",
    "        self.vocabulary = None\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        \"\"\"\n",
    "        Fits the CountVectorizer on the provided corpus.\n",
    "\n",
    "        Input:\n",
    "            corpus (list): A list of strings where each string represents\n",
    "            a sequence.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the corpus is empty or if any sequence\n",
    "            in the corpus is not a string or has length less than ngram_size.\n",
    "        \"\"\"\n",
    "        if not corpus:\n",
    "            raise ValueError(\"The corpus can't be empty.\")\n",
    "\n",
    "        tokens = set()\n",
    "        max_len_sequence = max(len(sequence) for sequence in corpus)\n",
    "        for sequence in corpus:\n",
    "            if (not isinstance(sequence, str) or max_len_sequence < self.ngram_size):\n",
    "                raise ValueError(\"Sequences must be strings of length at least ngram_size.\")\n",
    "            sequence = sequence.lower()\n",
    "            for token in range(len(sequence) - self.ngram_size + 1):\n",
    "                tokens.add(sequence[token : token + self.ngram_size])\n",
    "        self.vocabulary = {token: index for index, token in enumerate(sorted(tokens))}\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        \"\"\"\n",
    "        Transforms the provided corpus into numerical vectors based on\n",
    "        the fitted vocabulary.\n",
    "\n",
    "        Input:\n",
    "            corpus (list): A list of strings where each string represents\n",
    "            a sequence.\n",
    "\n",
    "        Output:\n",
    "            transformed_corpus (list): A list of numerical vectors\n",
    "            representing the sequences.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the corpus has not been fitted yet.\n",
    "        \"\"\"\n",
    "        if self.vocabulary is None:\n",
    "            raise ValueError(\"The corpus hasn't been fitted yet.\")\n",
    "\n",
    "        transformed_corpus = []\n",
    "        for sequence in corpus:\n",
    "            sequence = sequence.lower()\n",
    "            token_counter = [0] * len(self.vocabulary)\n",
    "            for i in range(len(sequence) - self.ngram_size + 1):\n",
    "                token = sequence[i : i + self.ngram_size]\n",
    "                if token in self.vocabulary:\n",
    "                    token_counter[self.vocabulary[token]] += 1\n",
    "            transformed_corpus.append(token_counter)\n",
    "        return transformed_corpus\n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        \"\"\"\n",
    "        Fits the CountVectorizer on the provided corpus and then transforms\n",
    "        the corpus into numerical vectors.\n",
    "\n",
    "        Input:\n",
    "            corpus (list): A list of strings where each string represents\n",
    "            a sequence.\n",
    "\n",
    "        Output:\n",
    "        transformed_corpus (list): A list of numerical vectors representing\n",
    "        the sequences.\n",
    "        \"\"\"\n",
    "        self.fit(corpus)\n",
    "        return self.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CountVectorizer output:\n",
      "[[0 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1]\n",
      " [1 1 1 0 0 1 0 1 0 1 2 0 0 0 0 0 0 1 1 1 1 1 0]]\n",
      "\n",
      "Sklearn's CountVectorizer output:\n",
      "[[0 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1]\n",
      " [1 1 1 0 0 1 0 1 0 1 2 0 0 0 0 0 0 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer as SklearnCountVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"Hello, world!\",\n",
    "    \"This is a test.\"\n",
    "]\n",
    "\n",
    "# Custom CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_size=3)\n",
    "transformed_corpus = vectorizer.fit_transform(corpus)\n",
    "print(\"Custom CountVectorizer output:\")\n",
    "print(np.array(transformed_corpus))\n",
    "print()\n",
    "\n",
    "# Sklearn's CountVectorizer\n",
    "sklearn_vectorizer = SklearnCountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "sklearn_transformed_corpus = sklearn_vectorizer.fit_transform(corpus).toarray()\n",
    "print(\"Sklearn's CountVectorizer output:\")\n",
    "print(sklearn_transformed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the outputs the same?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if the outputs are the same\n",
    "outputs_are_equal = np.array_equal(transformed_corpus, sklearn_transformed_corpus)\n",
    "print(f\"Are the outputs the same?\")\n",
    "print(outputs_are_equal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
